{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Suitable Job Lister"
      ],
      "metadata": {
        "id": "THY6UY_qgoQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraper"
      ],
      "metadata": {
        "id": "Q7oMQcmBeWsO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk_wcNQueMqE",
        "outputId": "abcd8af9-e1fd-4364-ded7-26b1b4abe441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-jobspy in /usr/local/lib/python3.10/dist-packages (1.1.75)\n",
            "Requirement already satisfied: NUMPY==1.26.3 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (1.26.3)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (4.12.3)\n",
            "Requirement already satisfied: markdownify<0.14.0,>=0.13.1 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (0.13.1)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (2.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (2.9.2)\n",
            "Requirement already satisfied: regex<2025.0.0,>=2024.4.28 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (2024.9.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (2.32.3)\n",
            "Requirement already satisfied: tls-client<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from python-jobspy) (1.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->python-jobspy) (2.6)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.10/dist-packages (from markdownify<0.14.0,>=0.13.1->python-jobspy) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.0->python-jobspy) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.3.0->python-jobspy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.3.0->python-jobspy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.3.0->python-jobspy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->python-jobspy) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U python-jobspy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from jobspy import scrape_jobs\n",
        "\n",
        "def scraper(jobtitle=None,pref_country=None,pref_area=None,no_of_output=300):\n",
        "  if jobtitle==None:\n",
        "    if pref_country==None:\n",
        "      if pref_area==None:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          )\n",
        "      else:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          location=pref_area\n",
        "          )\n",
        "    else:\n",
        "      if pref_area==None:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          country_indeed=pref_country\n",
        "          )\n",
        "      else:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          country_indeed=pref_country,\n",
        "          location=pref_area\n",
        "          )\n",
        "  else:\n",
        "    if pref_country==None:\n",
        "      if pref_area==None:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          search_term=jobtitle,\n",
        "          google_search_term=jobtitle,\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          )\n",
        "      else:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          search_term=jobtitle,\n",
        "          google_search_term=jobtitle,\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          location=pref_area\n",
        "          )\n",
        "    else:\n",
        "      if pref_area==None:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          search_term=jobtitle,\n",
        "          google_search_term=jobtitle,\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          country_indeed=pref_country\n",
        "          )\n",
        "      else:\n",
        "        jobs = scrape_jobs(\n",
        "          site_name=[\"indeed\", \"linkedin\", \"zip_recruiter\", \"glassdoor\", \"google\"],\n",
        "          search_term=jobtitle,\n",
        "          google_search_term=jobtitle,\n",
        "          results_wanted=no_of_output,\n",
        "          hours_old=72,\n",
        "          country_indeed=pref_country,\n",
        "          location=pref_area,\n",
        "          )\n",
        "  return jobs\n",
        "\n",
        "# jobs=scraper(jobtitle='UI/UX Developer',pref_country='India')\n",
        "# print(f\"Found {len(jobs)} jobs\")\n",
        "# print(jobs.head())\n",
        "# jobs.to_csv(\"jobs.csv\", quoting=csv.QUOTE_NONNUMERIC, escapechar=\"\\\\\", index=False)"
      ],
      "metadata": {
        "id": "DRYFTCBDexLd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resume Processing"
      ],
      "metadata": {
        "id": "x_sxI0Gf_XB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWWbVVlg_WMp",
        "outputId": "aab55b63-8bf5-40b8-cdab-6ff50142820e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def ResumeReader():\n",
        "  reader = PdfReader(\"Resume.pdf\")\n",
        "  number_of_pages = len(reader.pages)\n",
        "  text = \"\"\n",
        "  for i in range(number_of_pages):\n",
        "      page = reader.pages[i]\n",
        "      text += page.extract_text()\n",
        "  return text"
      ],
      "metadata": {
        "id": "9qoJb_wQ_fua"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PreProcessing"
      ],
      "metadata": {
        "id": "7h3CgxH2ARkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def preprocess_scraped_data(jobs):\n",
        "  cols_to_remove = ['site', 'job_url', 'job_url_direct', 'date_posted', 'emails', 'company_url', 'company_logo', 'company_url_direct']\n",
        "\n",
        "  new_jobs = jobs.drop(columns=cols_to_remove, errors='ignore')\n",
        "\n",
        "  new_jobs['combined_text'] = new_jobs.drop(columns=['id']).astype(str).apply(' '.join, axis=1)\n",
        "\n",
        "  new_jobs = new_jobs.drop_duplicates(subset=['combined_text'])\n",
        "\n",
        "  return new_jobs"
      ],
      "metadata": {
        "id": "GETkSun5AOW7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string"
      ],
      "metadata": {
        "id": "qtx8XG--AVFC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stop_words=set(stopwords.words('english'))\n",
        "punctuation=set(string.punctuation)\n",
        "lemmatizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZZKBiAWCAep",
        "outputId": "40c61fc7-56a4-4b37-d009-3f6fdb1c855b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_resume(text):\n",
        "  tokens=word_tokenize(text.lower())\n",
        "  tokens=[word for word in tokens if word not in stop_words and word not in punctuation and word.isalnum()]\n",
        "  tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
        "  return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "q3ehaIKPCK2-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jobs=scraper(jobtitle='civil engineer',pref_country='Germany')\n",
        "new_jobs=preprocess_scraped_data(jobs)\n",
        "text=ResumeReader()\n",
        "new_text=preprocessed_resume=preprocess_resume(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDUMJkMjDMsX",
        "outputId": "1d43a4d0-566e-4fe5-e616-4718d61bab22"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-16 08:22:35,336 - INFO - JobSpy:Indeed - search page: 1 / 3\n",
            "2024-11-16 08:22:35,344 - INFO - JobSpy:LinkedIn - search page: 1 / 30\n",
            "2024-11-16 08:22:35,477 - INFO - JobSpy:Glassdoor - search page: 1 / 11\n",
            "2024-11-16 08:22:35,500 - INFO - JobSpy:ZipRecruiter - search page: 1 / 15\n",
            "2024-11-16 08:22:35,506 - INFO - JobSpy:Indeed - found no jobs on page: 1\n",
            "2024-11-16 08:22:35,507 - INFO - JobSpy:Indeed - finished scraping\n",
            "2024-11-16 08:22:35,726 - INFO - JobSpy:Google - search page: 1 / 30\n",
            "2024-11-16 08:22:36,317 - INFO - JobSpy:Google - search page: 2 / 30\n",
            "2024-11-16 08:22:36,747 - INFO - JobSpy:Google - search page: 3 / 30\n",
            "2024-11-16 08:22:36,983 - INFO - JobSpy:Google - search page: 4 / 30\n",
            "2024-11-16 08:22:37,055 - INFO - JobSpy:Glassdoor - search page: 2 / 11\n",
            "2024-11-16 08:22:37,249 - INFO - JobSpy:Google - search page: 5 / 30\n",
            "2024-11-16 08:22:37,503 - INFO - JobSpy:Google - search page: 6 / 30\n",
            "2024-11-16 08:22:37,700 - INFO - JobSpy:Glassdoor - search page: 3 / 11\n",
            "2024-11-16 08:22:37,800 - INFO - JobSpy:Google - search page: 7 / 30\n",
            "2024-11-16 08:22:38,106 - INFO - JobSpy:Google - search page: 8 / 30\n",
            "2024-11-16 08:22:38,473 - INFO - JobSpy:Google - search page: 9 / 30\n",
            "2024-11-16 08:22:38,575 - INFO - JobSpy:Glassdoor - search page: 4 / 11\n",
            "2024-11-16 08:22:38,793 - INFO - JobSpy:Google - search page: 10 / 30\n",
            "2024-11-16 08:22:39,063 - INFO - JobSpy:Google - search page: 11 / 30\n",
            "2024-11-16 08:22:39,317 - INFO - JobSpy:Glassdoor - finished scraping\n",
            "2024-11-16 08:22:39,368 - INFO - JobSpy:Google - search page: 12 / 30\n",
            "2024-11-16 08:22:39,680 - INFO - JobSpy:Google - search page: 13 / 30\n",
            "2024-11-16 08:22:40,000 - INFO - JobSpy:Google - search page: 14 / 30\n",
            "2024-11-16 08:22:40,355 - INFO - JobSpy:Google - search page: 15 / 30\n",
            "2024-11-16 08:22:40,703 - INFO - JobSpy:Google - search page: 16 / 30\n",
            "2024-11-16 08:22:40,981 - INFO - JobSpy:Google - finished scraping\n",
            "2024-11-16 08:22:41,451 - INFO - JobSpy:ZipRecruiter - search page: 2 / 15\n",
            "2024-11-16 08:22:47,055 - INFO - JobSpy:ZipRecruiter - search page: 3 / 15\n",
            "2024-11-16 08:22:47,367 - INFO - JobSpy:ZipRecruiter - finished scraping\n",
            "2024-11-16 08:22:50,444 - INFO - JobSpy:LinkedIn - search page: 2 / 30\n",
            "2024-11-16 08:23:20,820 - ERROR - JobSpy:LinkedIn - LinkedIn: HTTPSConnectionPool(host='www.linkedin.com', port=443): Max retries exceeded with url: /jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=civil+engineer&distance=50&pageNum=0&start=10&f_TPR=r259200 (Caused by ResponseError('too many 429 error responses'))\n",
            "2024-11-16 08:23:20,822 - INFO - JobSpy:Linkedin - finished scraping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_jobs.head())\n",
        "print(new_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRodTFxFEhMZ",
        "outputId": "7415d560-a44c-47c8-e8f3-9148b073390a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 id                              title  \\\n",
            "0  gd-1009529352273               Project Engineer Dam   \n",
            "1  gd-1009529598135              Geotechnical Engineer   \n",
            "2  gd-1009529203148  Senior Transmission Line Engineer   \n",
            "3  gd-1009529644558         Commercial Project Manager   \n",
            "4  gd-1009529589121                Structural Engineer   \n",
            "\n",
            "                       company         location job_type salary_source  \\\n",
            "0     Wazeer Khan & Abbas Khan              NaN      NaN   direct_data   \n",
            "1                   CAMPOS EPC              NaN      NaN   direct_data   \n",
            "2               b19 consulting              NaN      NaN   direct_data   \n",
            "3  Alpine Ocean Seismic Survey              NaN      NaN           NaN   \n",
            "4                  CyberCoders  Jersey City, NJ      NaN   direct_data   \n",
            "\n",
            "  interval  min_amount  max_amount currency  ... job_level job_function  \\\n",
            "0   yearly    110000.0    135000.0      USD  ...       NaN         None   \n",
            "1   yearly     75000.0     90000.0      USD  ...       NaN         None   \n",
            "2   yearly    130000.0    165000.0      USD  ...       NaN         None   \n",
            "3      NaN         NaN         NaN      NaN  ...       NaN         None   \n",
            "4   yearly    130000.0    140000.0      USD  ...       NaN         None   \n",
            "\n",
            "  listing_type                                        description  \\\n",
            "0      organic  PE Project Dam Engineer\\n\\nLocation : New Hamp...   \n",
            "1      organic  Campos EPC continues to expand and is seeking ...   \n",
            "2      organic  **Senior Transmission Line Engineer \\- $130,00...   \n",
            "3      organic  **About Alpine Ocean Seismic Survey**\\nAlpine ...   \n",
            "4    sponsored  Structural Engineer\\nIf you are a Structural E...   \n",
            "\n",
            "  company_industry company_addresses company_num_employees company_revenue  \\\n",
            "0             None              None                  None            None   \n",
            "1             None              None                  None            None   \n",
            "2             None              None                  None            None   \n",
            "3             None              None                  None            None   \n",
            "4             None              None                  None            None   \n",
            "\n",
            "  company_description                                      combined_text  \n",
            "0                None  Project Engineer Dam Wazeer Khan & Abbas Khan ...  \n",
            "1                None  Geotechnical Engineer CAMPOS EPC nan nan direc...  \n",
            "2                None  Senior Transmission Line Engineer b19 consulti...  \n",
            "3                None  Commercial Project Manager Alpine Ocean Seismi...  \n",
            "4                None  Structural Engineer CyberCoders Jersey City, N...  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "aldrin shanty software engineer aldrinshanty22 8943980001 kochi kerala india 22 mar 2004 profile passionate curious computer science enthusiast strong drive continuous learning exploration field eager expand knowledge skill dedicated staying updated latest technology trend thrive solving complex problem enjoy taking challenging project push boundary understanding education christ university btech computer science engineering specialisation artificial intelligence machine learning2022 present bangalore india st antony public school higher secondary education 2020 2022 kottayam india viswajyothi cmi public school secondary education 2019 2020 angamaly india professional experience codecraft ai solution pvt ltd machine learning intern may 2024 trivandrum india neuflo solution pvt ltd machine learning intern may 2023 oct 2023 ernakulam india skill python advanced oop decorator lambda web development django data analysis panda numpy machine learning dbms normalization sql oracle postgresql nosql mongodb javascript advanced class prototype chain typed array web development event handler dom manipulation git github commits structured format conventional commits language english malayalamhindi declaration hereby declare information provided true correct best knowledge belief aldrin shanty kochi kerala india july 8 2024\n"
          ]
        }
      ]
    }
  ]
}